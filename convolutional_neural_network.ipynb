{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b57bf417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def image2col(x, filter_size: Tuple, pad=0, stride=1):   \n",
    "    assert len(x.shape) == 4, f\"Input data should have 4 dimensions, but got {len(x.shape)} dimensions\"\n",
    "    \n",
    "    B, C, H, W = x.shape\n",
    "\n",
    "    out_h = (H + 2*pad - filter_size[0]) // stride + 1\n",
    "    out_w = (W + 2*pad - filter_size[1]) // stride + 1\n",
    "    \n",
    "    x_pad = np.pad(sample_data, [(0, 0), (0, 0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((B, C, filter_size[0], filter_size[1], out_h, out_w))\n",
    "\n",
    "    for y in range(filter_size[0]):\n",
    "        y_max = y + stride * out_h\n",
    "\n",
    "        for x in range(filter_size[1]):\n",
    "            x_max = x + stride * out_w\n",
    "\n",
    "            col[:, :, y, x, :, :] = x_pad[:, :, y:y_max:stride, x:x_max:stride]\n",
    "    \n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(B * out_h * out_w, -1)\n",
    "    \n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94af9357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1, 28, 28)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "data = FashionMNIST(root=\".\", download=True)\n",
    "sample_data = data.data[:32]\n",
    "sample_data = sample_data.unsqueeze(1).numpy()\n",
    "\n",
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "828505b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21632, 9)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_image = image2col(sample_data, (3, 3), pad=0, stride=1)\n",
    "transformed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "744bf92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Covolution:\n",
    "    def __init__(self, W, b, stride, pad):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.w.shape\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        col = image2col(x)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6bb3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, kernel_size: Tuple, stride=1, pad=0):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        out_h = int(1 + (H - self.kernel_size[0]) / self.stride)\n",
    "        out_w = int(1 + (W - self.kernel_size[1]) / self.stride)\n",
    "        \n",
    "        col = image2col(x, self.kernel_size[0], self.kernel_size[1], self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.kernel_size[0] * self.kernel_size[1])\n",
    "        \n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        out = out.reshape(B, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9136eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                conv_param={\"filter_num\": 30, \"filter_size\": 5,\n",
    "                            \"pad\": 100, \"stride\": 1},\n",
    "                hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "    \n",
    "        self.filter_num = conv_param[\"filter_num\"]\n",
    "        self.filter_size = conv_param[\"filter_size\"]\n",
    "        self.filter_pad = conv_param[\"pad\"]\n",
    "        self.filter_stride = conv_param[\"stride\"]\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        input_size = input_dim[1]\n",
    "        \n",
    "        conv_output_size = (input_size - filter_size + 2 * filter_pad) / filter_stride + 1\n",
    "        pad_output_size = int(filter_num * (conv_output_size / 2) * (conv_output_size / 2))\n",
    "        \n",
    "        \n",
    "        self.__weight_init(weight_init_std)\n",
    "    \n",
    "    def __define_layers(self):\n",
    "        self.layers = OrderedDict()\n",
    "        \n",
    "        self.layers[\"Conv1\"] = Convolution(self.param[\"W1\"],\n",
    "                                           self.param[\"b1\"],\n",
    "                                           self.filter_stride,\n",
    "                                           self.filter_pad)\n",
    "        \n",
    "        self.layers[\"Relu1\"] = Relu()\n",
    "        self.layers[\"Pool1\"] = Pooling(kernel_size=(2, 2), stride=2)\n",
    "        self.layers[\"FC1\"] = Affine(self.param[\"W2\"], self.param[\"b2\"])\n",
    "        self.layers[\"Relu2\"] = Relu()\n",
    "        self.layers[\"FC2\"] = Affine(self.param[\"W3\"], self.param[\"b3\"])\n",
    "        self.layers[\"Out\"] = SoftmaxWithLoss()\n",
    "        \n",
    "    \n",
    "    def __weight_init(self, weight_init_std):\n",
    "        self.param = {}\n",
    "        \n",
    "        # Conv layer\n",
    "        self.param[\"W1\"] = weight_init_std * np.random.randn(self.filter_num, self.input_dim[0], \n",
    "                                                             filter_size, filter_size)\n",
    "        self.param[\"b1\"] = np.zeros(filter_size)\n",
    "        \n",
    "        # FC layer 1\n",
    "        self.param[\"W2\"] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "        self.param[\"b2\"] = np.zeros(hidden_size)\n",
    "\n",
    "        # FC layer 2\n",
    "        self.param[\"W3\"] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.param[\"b3\"] = np.zeros(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4141e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Affine layer\n",
    "# Relu layer\n",
    "# SoftmaxWithLoss layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
